- name: Model Environment Deployment & Activation
  hosts: all
  
  # vars_prompt:
  #   - name: tag
  #     prompt: please enter the type of model.
  #     private: no
  
  vars:
    image_name: "{{ ansible_facts['architecture'] }}-model"
    model_tag: "imagenet"
    input: "test.jpg"
    registry: "123.214.186.252:39500"
    server: keti@ketiabcs.iptime.org
    version: v1.0
    ansible_become: true
    ansible_user: keti
    ansible_become_method: sudo
    ansible_become_pass: ketiabcs
    server_name: None
    server_port: None
    sv_private_ip: None
    num_clients: 2
    num_rounds: 5
    tb_port: 6006
    teacher: True

  
  tasks:


#==================================== distribution =====================================
#=======================================================================================

  - name: pull docker model image from dockerhub
    tags: distrb
    shell: docker pull {{ registry }}/{{ image_name }}:{{ model_tag }}-{{ version }}
    register: output
  - debug: msg="{{ output.stdout_lines }}"
    tags: distrb

  - name: clear containers named identical
    tags: distrb
    shell: docker stop {{ model_tag }}-model-{{ version }} && docker rm {{ model_tag }}-model-{{ version }}
    register: output
    ignore_errors: yes
  - debug: msg="{{ output.stdout_lines }}"
    tags: distrb


### different types of build script

## 1. flower fed-learn sever
  - name: create new AI model env container
    tags: distrb
    shell: docker run -d -p {{ server_port }}:{{ server_port }} -p {{ tb_port }}:{{ tb_port }} -v "$(pwd)"/ethicsense/flwr_logs:/home/flwr_logs --name {{ model_tag }}-model-{{ version }} -it {{ registry }}/{{ image_name }}:{{ model_tag }}-{{ version }}
    register: output
  - debug: msg="{{ output.stdout_lines }}"
    tags: distrb

## 2. gradio, flask, etc AI model app
  # - name: create new AI model env container
  #   tags: distrb
  #   shell: docker run -d -p {{ server_port }}:{{ server_port }} -v "$(pwd)"/weights:/weights --name {{ model_tag }}-model-{{ version }} -it {{ registry }}/{{ image_name }}:{{ model_tag }}-{{ version }}
  #   register: output
  # - debug: msg="{{ output.stdout_lines }}"
  #   tags: distrb


#==================================== show results =====================================
#=======================================================================================

  - name: clusters' docker image list verification
    tags: search
    shell: docker images
    register: output
  - debug: msg="{{ output.stdout_lines }}"
    tags: search

  - name: clusters' model env container list verification
    tags: search
    shell: docker ps -a
    register: output
  - debug: msg="{{ output.stdout_lines }}"
    tags: search



#===================================== get input =======================================
#=======================================================================================

  - name: input from server to node
    tags: input
    copy:
      src: "/var/www/html/tmp/{{ input }}"
      dest: data/

  - name: input from node to model container
    tags: input
    command: docker cp data/{{ input }} {{ model_tag }}-model:/home/data/
    register: command_output
  - debug: msg="{{command_output.stdout_lines}}"
    tags: input



#===================================== AI model run =======================================#
#==========================================================================================#

  ## run model predictor
  - name: model prediction
    tags: pred
    command: docker exec {{ model_tag }}-model python home/model.py --input {{ input }} --mod pred
    register: command_output
  - debug: msg="{{command_output.stdout_lines}}"
    tags: pred

  ## run model trainer
  - name: model train
    tags: train
    command: docker exec {{ model_tag }}-model python home/model.py --input {{ input }} --mod train
    register: command_output
  - debug: msg="{{ command_ouput.stdout_lines }}"
    tags: train




#===================================== Run Gradio dem0 =======================================#
#=============================================================================================#

  - name: gradio server activation
    tags: gradio
    command: docker exec -d {{ model_tag }}-model-{{ version }} python app.py --server_name {{ server_name }} --server_port {{ server_port }}
    register: output
  - debug: msg="{{ output.stdout_lines }}"
    tags: gradio



#==================================== Run Flask dem0 ===========================================#
#===============================================================================================#

  - name: Flask server activation
    tags: flask
    command: docker exec -d {{ model_tag }}-model-{{ version }} python run.py --server_name {{ server_name }} --server_port {{ server_port }}
    register: output
  - debug: msg="{{ output.stdout_lines }}"
    tags: flask


#============================ Run Flower dem0 (server-client ver.)==================================#
#===================================================================================================#

  - name: Flower FL-train activation ( teacher )
    tags: flower
    command: docker exec -d {{ model_tag }}-model-{{ version }} python server.py --server_port {{ server_port }} --num_clients {{ num_clients }} --num_rounds {{ num_rounds }} --tb_port {{ tb_port }}
    when: inventory_hostname in groups["fl_teacher"]
    register: output
  - debug: msg="{{ output.stdout_lines }}"
    tags: flower
    when: inventory_hostname in groups["fl_teacher"]

  - name: Flower FL-train activation ( student )
    tags: flower
    command: docker exec {{ model_tag }}-model-{{ version }} python client.py --server_address {{ sv_private_ip }}:{{ server_port }}
    register: output
    when: inventory_hostname in groups["fl_student"]
  - debug: msg="{{ output.stdout_lines }}"
    tags: flower
    when: inventory_hostname in groups["fl_student"]



#============================ Run Flower dem0 (ray simulation ver.)==================================#
#====================================================================================================#

  - name: Flower FL-train ray server activation
    tags: flwrsim
    command: docker exec {{ model_tag }}-model-{{ version }} ray start --head --node-ip-address 0.0.0.0 --dashboard-host 0.0.0.0 --dashboard-port {{ server_port }}
    register: output
    when: inventory_hostname in groups["fl_teacher"]
  - debug: msg="{{ output.stdout_lines }}"
    tags: flwrsim
    when: inventory_hostname in groups["fl_teacher"]

  - name: Pause til server set
    tags: flwrsim
    pause:
      seconds: 20

  - name: Flower FL-train ray client activation
    tags: flwrsim
    command: docker exec {{ model_tag }}-model-{{ version }} ray start --address {{ sv_private_ip }}:6379
    register: output
    when: inventory_hostname in groups["fl_student"]
  - debug: msg="{{ output.stdout_lines }}"
    tags: flwrsim
    when: inventory_hostname in groups["fl_student"]

  - name: Pause til clients set
    tags: flwrsim
    pause:
      seconds: 20

  - name: Start Flower training simulation
    tags: flwrsim
    command: docker exec {{ model_tag }}-model-{{ version }} python sim.py --num_rounds 10 --multi_node 1 --num_cpus 10
    register: output
    when: inventory_hostname in groups["fl_teacher"]
  - debug: msg="{{ output.stdout_lines }}"
    tags: flwrsim
    when: inventory_hostname in groups["fl_teacher"]



#============================== Weights switching fucntion =====================================#
#===============================================================================================#

  - name: weights directory setting
    tags: weights_set
    copy:
      src: "{{ weight_dir }}"
      dest: /home/keti/

  - name: add weight file
    tags: weights_add
    copy:
      src: "{{ awd }}/{{ weight_file }}"
      dest: /home/keti/weights
