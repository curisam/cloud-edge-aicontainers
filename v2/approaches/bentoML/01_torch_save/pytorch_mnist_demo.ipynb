{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a682ea0b",
   "metadata": {},
   "source": [
    "# BentoML PyTorch MNIST Tutorial\n",
    "\n",
    "Link to source code: https://github.com/bentoml/BentoML/tree/main/examples/pytorch_mnist/\n",
    "\n",
    "Install required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad00863",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45393b74",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "First let's define a simple PyTorch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caeff07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple Convolutional Neural Network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(26 * 26 * 10, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def predict(self, inp):\n",
    "        \"\"\"predict digit for input\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            raw_output = self(inp)\n",
    "            _, pred = torch.max(raw_output, 1)\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38888f0a",
   "metadata": {},
   "source": [
    "## Training and Saving the model\n",
    "\n",
    "Then we define a simple PyTorch network and some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62db15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import bentoml\n",
    "\n",
    "# reproducible setup for testing\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def _dataloader_init_fn(worker_id):\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539b5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLDS = 5\n",
    "NUM_EPOCHS = 5\n",
    "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    # Prepare MNIST dataset by concatenating Train/Test part; we split later.\n",
    "    train_set = MNIST(\n",
    "        os.getcwd(), download=True, transform=transforms.ToTensor(), train=True\n",
    "    )\n",
    "    test_set = MNIST(\n",
    "        os.getcwd(), download=True, transform=transforms.ToTensor(), train=False\n",
    "    )\n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, loss_function, train_loader, epoch, device=\"cpu\"):\n",
    "    # Mark training flag\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 499 == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(inputs),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, device=\"cpu\"):\n",
    "    correct, total = 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2db4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02700495719909668,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9912422,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af399ae33ec43e0a7442d5c70c65483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw/train-images-idx3-ubyte.gz to /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010704278945922852,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 28881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bb7a5a67ef499d9c4d7895ea5014ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024996042251586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1648877,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af264180dc1c46eea9ee103894e880d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02417778968811035,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4542,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a50bae44b340358bd43fd022e4d15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_set, test_set = get_dataset()\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=10,\n",
    "    sampler=torch.utils.data.RandomSampler(test_set),\n",
    "    worker_init_fn=_dataloader_init_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c19a0",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "We can do some cross validation and the results can be saved with the model as metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2fdd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(dataset, epochs=NUM_EPOCHS, k_folds=K_FOLDS):\n",
    "    results = {}\n",
    "\n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "        print(f\"FOLD {fold}\")\n",
    "        print(\"--------------------------------\")\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=10,\n",
    "            sampler=train_subsampler,\n",
    "            worker_init_fn=_dataloader_init_fn,\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=10,\n",
    "            sampler=test_subsampler,\n",
    "            worker_init_fn=_dataloader_init_fn,\n",
    "        )\n",
    "\n",
    "        # Train this fold\n",
    "        model = SimpleConvNet()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        for epoch in range(epochs):\n",
    "            train_epoch(model, optimizer, loss_function, train_loader, epoch)\n",
    "\n",
    "        # Evaluation for this fold\n",
    "        correct, total = test_model(model, test_loader)\n",
    "        print(\"Accuracy for fold %d: %d %%\" % (fold, 100.0 * correct / total))\n",
    "        print(\"--------------------------------\")\n",
    "        results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "    # Print fold results\n",
    "    print(f\"K-FOLD CROSS VALIDATION RESULTS FOR {K_FOLDS} FOLDS\")\n",
    "    print(\"--------------------------------\")\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f\"Fold {key}: {value} %\")\n",
    "        sum += value\n",
    "\n",
    "    print(f\"Average: {sum/len(results.items())} %\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd06de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.273126\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 1.362214\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.411741\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 1.001387\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.102832\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.511123\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.054133\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.228040\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.370208\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.128680\n",
      "Accuracy for fold 0: 91 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.327491\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 1.318107\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.485992\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 1.216311\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.419983\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.758953\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.147877\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.171751\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.317925\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.670030\n",
      "Accuracy for fold 1: 91 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.218862\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 1.440863\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.390614\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 0.372517\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.524596\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.206332\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.041541\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.221805\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.570446\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.220445\n",
      "Accuracy for fold 2: 90 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.316931\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 0.965537\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.240633\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 0.375479\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.150217\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.608828\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.035714\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.419792\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.178606\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.158449\n",
      "Accuracy for fold 3: 92 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.352834\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 0.953529\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.918020\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 0.850265\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.246312\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.234261\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.446011\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.225173\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.253967\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.179806\n",
      "Accuracy for fold 4: 90 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 91.10833333333333 %\n",
      "Fold 1: 91.30833333333334 %\n",
      "Fold 2: 90.83333333333333 %\n",
      "Fold 3: 92.05833333333334 %\n",
      "Fold 4: 90.85 %\n",
      "Average: 91.23166666666665 %\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(train_set, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2104a6",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d311c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs=NUM_EPOCHS, device=\"cpu\"):\n",
    "\n",
    "    train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=10,\n",
    "        sampler=train_sampler,\n",
    "        worker_init_fn=_dataloader_init_fn,\n",
    "    )\n",
    "    model = SimpleConvNet()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_epoch(model, optimizer, loss_function, train_loader, epoch, device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8df05c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.371420\n",
      "Train Epoch: 0 [4990/60000 (8%)]\tLoss: 1.000866\n",
      "Train Epoch: 0 [9980/60000 (17%)]\tLoss: 1.110684\n",
      "Train Epoch: 0 [14970/60000 (25%)]\tLoss: 0.737675\n",
      "Train Epoch: 0 [19960/60000 (33%)]\tLoss: 0.364442\n",
      "Train Epoch: 0 [24950/60000 (42%)]\tLoss: 0.390488\n",
      "Train Epoch: 0 [29940/60000 (50%)]\tLoss: 0.282015\n",
      "Train Epoch: 0 [34930/60000 (58%)]\tLoss: 0.199642\n",
      "Train Epoch: 0 [39920/60000 (67%)]\tLoss: 0.367593\n",
      "Train Epoch: 0 [44910/60000 (75%)]\tLoss: 0.554671\n",
      "Train Epoch: 0 [49900/60000 (83%)]\tLoss: 0.017668\n",
      "Train Epoch: 0 [54890/60000 (91%)]\tLoss: 0.086637\n",
      "Train Epoch: 0 [59880/60000 (100%)]\tLoss: 0.249382\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.222885\n",
      "Train Epoch: 1 [4990/60000 (8%)]\tLoss: 0.288008\n",
      "Train Epoch: 1 [9980/60000 (17%)]\tLoss: 0.151059\n",
      "Train Epoch: 1 [14970/60000 (25%)]\tLoss: 0.118367\n",
      "Train Epoch: 1 [19960/60000 (33%)]\tLoss: 0.757163\n",
      "Train Epoch: 1 [24950/60000 (42%)]\tLoss: 0.100751\n",
      "Train Epoch: 1 [29940/60000 (50%)]\tLoss: 0.131567\n",
      "Train Epoch: 1 [34930/60000 (58%)]\tLoss: 1.147586\n",
      "Train Epoch: 1 [39920/60000 (67%)]\tLoss: 0.029441\n",
      "Train Epoch: 1 [44910/60000 (75%)]\tLoss: 0.175337\n",
      "Train Epoch: 1 [49900/60000 (83%)]\tLoss: 0.096961\n",
      "Train Epoch: 1 [54890/60000 (91%)]\tLoss: 0.553874\n",
      "Train Epoch: 1 [59880/60000 (100%)]\tLoss: 0.014491\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.116300\n",
      "Train Epoch: 2 [4990/60000 (8%)]\tLoss: 0.009910\n",
      "Train Epoch: 2 [9980/60000 (17%)]\tLoss: 0.034026\n",
      "Train Epoch: 2 [14970/60000 (25%)]\tLoss: 0.111336\n",
      "Train Epoch: 2 [19960/60000 (33%)]\tLoss: 0.126248\n",
      "Train Epoch: 2 [24950/60000 (42%)]\tLoss: 0.103683\n",
      "Train Epoch: 2 [29940/60000 (50%)]\tLoss: 0.008613\n",
      "Train Epoch: 2 [34930/60000 (58%)]\tLoss: 0.268812\n",
      "Train Epoch: 2 [39920/60000 (67%)]\tLoss: 0.122979\n",
      "Train Epoch: 2 [44910/60000 (75%)]\tLoss: 0.114664\n",
      "Train Epoch: 2 [49900/60000 (83%)]\tLoss: 0.120142\n",
      "Train Epoch: 2 [54890/60000 (91%)]\tLoss: 0.054167\n",
      "Train Epoch: 2 [59880/60000 (100%)]\tLoss: 0.675159\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.137271\n",
      "Train Epoch: 3 [4990/60000 (8%)]\tLoss: 0.255934\n",
      "Train Epoch: 3 [9980/60000 (17%)]\tLoss: 0.064276\n",
      "Train Epoch: 3 [14970/60000 (25%)]\tLoss: 0.059164\n",
      "Train Epoch: 3 [19960/60000 (33%)]\tLoss: 0.020650\n",
      "Train Epoch: 3 [24950/60000 (42%)]\tLoss: 0.024199\n",
      "Train Epoch: 3 [29940/60000 (50%)]\tLoss: 0.111855\n",
      "Train Epoch: 3 [34930/60000 (58%)]\tLoss: 0.091122\n",
      "Train Epoch: 3 [39920/60000 (67%)]\tLoss: 0.281566\n",
      "Train Epoch: 3 [44910/60000 (75%)]\tLoss: 0.017045\n",
      "Train Epoch: 3 [49900/60000 (83%)]\tLoss: 0.097771\n",
      "Train Epoch: 3 [54890/60000 (91%)]\tLoss: 0.044288\n",
      "Train Epoch: 3 [59880/60000 (100%)]\tLoss: 0.289735\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.491376\n",
      "Train Epoch: 4 [4990/60000 (8%)]\tLoss: 0.013874\n",
      "Train Epoch: 4 [9980/60000 (17%)]\tLoss: 0.092605\n",
      "Train Epoch: 4 [14970/60000 (25%)]\tLoss: 0.032414\n",
      "Train Epoch: 4 [19960/60000 (33%)]\tLoss: 0.050740\n",
      "Train Epoch: 4 [24950/60000 (42%)]\tLoss: 0.485823\n",
      "Train Epoch: 4 [29940/60000 (50%)]\tLoss: 0.142425\n",
      "Train Epoch: 4 [34930/60000 (58%)]\tLoss: 0.035510\n",
      "Train Epoch: 4 [39920/60000 (67%)]\tLoss: 0.309602\n",
      "Train Epoch: 4 [44910/60000 (75%)]\tLoss: 0.288165\n",
      "Train Epoch: 4 [49900/60000 (83%)]\tLoss: 0.180074\n",
      "Train Epoch: 4 [54890/60000 (91%)]\tLoss: 0.005685\n",
      "Train Epoch: 4 [59880/60000 (100%)]\tLoss: 0.012935\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9b23c",
   "metadata": {},
   "source": [
    "### saving the model with some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe9c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The \"bentoml.pytorch.save\" method is being deprecated. Use \"bentoml.pytorch.save_model\" instead\n"
     ]
    }
   ],
   "source": [
    "correct, total = test_model(trained_model, test_loader)\n",
    "metadata = {\n",
    "    \"accuracy\": float(correct) / total,\n",
    "    \"cv_stats\": cv_results,\n",
    "}\n",
    "\n",
    "tag = bentoml.pytorch.save(\n",
    "    \"pytorch_mnist\",\n",
    "    trained_model,\n",
    "    metadata=metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf35e55",
   "metadata": {},
   "source": [
    "## Create a BentoML Service for serving the model\n",
    "\n",
    "Note: using `%%writefile` here because `bentoml.Service` instance must be created in a separate `.py` file\n",
    "\n",
    "Even though we have only one model, we can create as many api endpoints as we want. Here we create two end points `predict_ndarray` and `predict_image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e2f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "\n",
    "import typing as t\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from PIL.Image import Image as PILImage\n",
    "\n",
    "import bentoml\n",
    "from bentoml.io import Image\n",
    "from bentoml.io import NumpyNdarray\n",
    "\n",
    "\n",
    "mnist_runner = bentoml.pytorch.load_runner(\n",
    "    \"pytorch_mnist\",\n",
    "    name=\"mnist_runner\",\n",
    "    predict_fn_name=\"predict\",\n",
    ")\n",
    "\n",
    "svc = bentoml.Service(\n",
    "    name=\"pytorch_mnist_demo\",\n",
    "    runners=[\n",
    "        mnist_runner,\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "@svc.api(\n",
    "    input=NumpyNdarray(dtype=\"float32\", enforce_dtype=True),\n",
    "    output=NumpyNdarray(dtype=\"int64\"),\n",
    ")\n",
    "async def predict_ndarray(\n",
    "    inp: \"np.ndarray[t.Any, np.dtype[t.Any]]\",\n",
    ") -> \"np.ndarray[t.Any, np.dtype[t.Any]]\":\n",
    "    assert inp.shape == (28, 28)\n",
    "    # We are using greyscale image and our PyTorch model expect one\n",
    "    # extra channel dimension\n",
    "    inp = np.expand_dims(inp, 0)\n",
    "    output_tensor = await mnist_runner.async_run(inp)\n",
    "    return output_tensor.numpy()\n",
    "\n",
    "\n",
    "@svc.api(input=Image(), output=NumpyNdarray(dtype=\"int64\"))\n",
    "async def predict_image(f: PILImage) -> \"np.ndarray[t.Any, np.dtype[t.Any]]\":\n",
    "    assert isinstance(f, PILImage)\n",
    "    arr = np.array(f)/255.0\n",
    "    assert arr.shape == (28, 28)\n",
    "\n",
    "    # We are using greyscale image and our PyTorch model expect one\n",
    "    # extra channel dimension\n",
    "    arr = np.expand_dims(arr, 0).astype(\"float32\")\n",
    "    output_tensor = await mnist_runner.async_run(arr)\n",
    "    return output_tensor.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590147aa",
   "metadata": {},
   "source": [
    "Start a dev model server to test out the service defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29173871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-29T23:14:00+0900 [ERROR] [cli] The \"bentoml.pytorch.load_runner\" method is being deprecated. \"load_runner\" arguments will be ignored. Use `bentoml.pytorch.get(\"pytorch_mnist\").to_runner()` instead\n",
      "2022-08-29T23:14:01+0900 [INFO] [cli] Starting development BentoServer from \"service.py:svc\" running on http://0.0.0.0:3000 (Press CTRL+C to quit)\n",
      "2022-08-29T23:14:02+0900 [ERROR] [dev_api_server] The \"bentoml.pytorch.load_runner\" method is being deprecated. \"load_runner\" arguments will be ignored. Use `bentoml.pytorch.get(\"pytorch_mnist\").to_runner()` instead\n",
      "2022-08-29T23:19:37+0900 [ERROR] [dev_api_server] Exception on /predict_image [POST] (trace=223488237310718307942399481219286090262,span=13763858875098358961,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/server/service_app.py\", line 318, in api_func\n",
      "    output = await api.func(input_data)\n",
      "  File \"/Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/service.py\", line 51, in predict_image\n",
      "    output_tensor = await mnist_runner.async_run(arr)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/runner/runner.py\", line 51, in async_run\n",
      "    return await self.runner._runner_handle.async_run_method(  # type: ignore\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/runner/runner_handle/local.py\", line 57, in async_run_method\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/runner/runnable.py\", line 139, in method\n",
      "    return self.func(obj, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/frameworks/common/pytorch.py\", line 103, in _run\n",
      "    return getattr(self.model, method_name)(*params.args, **params.kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/var/folders/pv/78hsfpv1623068f45h32ygw80000gn/T/ipykernel_16445/3113368347.py\", line 24, in forward\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (10x676 and 6760x50)\n",
      "2022-08-29T23:19:37+0900 [INFO] [dev_api_server] 127.0.0.1:54463 (scheme=http,method=POST,path=/predict_image,type=multipart/form-data; boundary=------------------------870d71512c232b11,length=304) (status=500,type=application/json,length=110) 83.363ms (trace=223488237310718307942399481219286090262,span=13763858875098358961,sampled=0)\n",
      "2022-08-29T23:19:41+0900 [ERROR] [dev_api_server] Exception on /predict_image [POST] (trace=244231631786957434586211006893355735533,span=12079206635371522288,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/server/service_app.py\", line 318, in api_func\n",
      "    output = await api.func(input_data)\n",
      "  File \"/Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/service.py\", line 51, in predict_image\n",
      "    output_tensor = await mnist_runner.async_run(arr)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/runner/runner.py\", line 51, in async_run\n",
      "    return await self.runner._runner_handle.async_run_method(  # type: ignore\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/runner/runner_handle/local.py\", line 57, in async_run_method\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/runner/runnable.py\", line 139, in method\n",
      "    return self.func(obj, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/frameworks/common/pytorch.py\", line 103, in _run\n",
      "    return getattr(self.model, method_name)(*params.args, **params.kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/var/folders/pv/78hsfpv1623068f45h32ygw80000gn/T/ipykernel_16445/3113368347.py\", line 24, in forward\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (10x676 and 6760x50)\n",
      "2022-08-29T23:19:41+0900 [INFO] [dev_api_server] 127.0.0.1:54579 (scheme=http,method=POST,path=/predict_image,type=multipart/form-data; boundary=------------------------5c1110b7f87bce75,length=304) (status=500,type=application/json,length=110) 6.376ms (trace=244231631786957434586211006893355735533,span=12079206635371522288,sampled=0)\n",
      "2022-08-29T23:19:45+0900 [INFO] [dev_api_server] 127.0.0.1:54684 (scheme=http,method=GET,path=/,type=,length=) (status=200,type=text/html; charset=utf-8,length=2859) 2.435ms (trace=150657643588600464077363217607811764543,span=15093084187064812838,sampled=0)\n",
      "2022-08-29T23:19:45+0900 [INFO] [dev_api_server] 127.0.0.1:54684 (scheme=http,method=GET,path=/static_content/index.css,type=,length=) (status=304,type=,length=) 13.012ms (trace=245424201007770244803448422216734641829,span=17752590011987541584,sampled=0)\n",
      "2022-08-29T23:19:45+0900 [INFO] [dev_api_server] 127.0.0.1:54685 (scheme=http,method=GET,path=/static_content/swagger-initializer.js,type=,length=) (status=304,type=,length=) 12.554ms (trace=103696352495228413556353581320556167293,span=15512567062184668560,sampled=0)\n",
      "2022-08-29T23:19:45+0900 [INFO] [dev_api_server] 127.0.0.1:54686 (scheme=http,method=GET,path=/static_content/swagger-ui.css,type=,length=) (status=304,type=,length=) 12.839ms (trace=324406471819118096814298610481517813908,span=17605366410113320605,sampled=0)\n",
      "2022-08-29T23:19:45+0900 [INFO] [dev_api_server] 127.0.0.1:54687 (scheme=http,method=GET,path=/static_content/swagger-ui-standalone-preset.js,type=,length=) (status=304,type=,length=) 12.306ms (trace=152884043453439510907734707543195830877,span=7974442990483314220,sampled=0)\n",
      "2022-08-29T23:19:45+0900 [INFO] [dev_api_server] 127.0.0.1:54688 (scheme=http,method=GET,path=/static_content/swagger-ui-bundle.js,type=,length=) (status=304,type=,length=) 12.238ms (trace=18529396405687892637169670541031094494,span=14717765294769485560,sampled=0)\n",
      "2022-08-29T23:19:45+0900 [INFO] [dev_api_server] 127.0.0.1:54684 (scheme=http,method=GET,path=/docs.json,type=,length=) (status=200,type=application/json,length=5373) 25.110ms (trace=301843538693331119059219991947398863917,span=7185307189929386727,sampled=0)\n",
      "2022-08-29T23:20:07+0900 [ERROR] [dev_api_server] Exception on /predict_ndarray [POST] (trace=327245884190547155217955169479307530104,span=3705020281566824112,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/server/service_app.py\", line 318, in api_func\n",
      "    output = await api.func(input_data)\n",
      "  File \"/Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/service.py\", line 34, in predict_ndarray\n",
      "    assert inp.shape == (28, 28)\n",
      "AssertionError\n",
      "2022-08-29T23:20:07+0900 [INFO] [dev_api_server] 127.0.0.1:55312 (scheme=http,method=POST,path=/predict_ndarray,type=application/json,length=7) (status=500,type=application/json,length=110) 2.765ms (trace=327245884190547155217955169479307530104,span=3705020281566824112,sampled=0)\n",
      "2022-08-29T23:20:09+0900 [ERROR] [dev_api_server] Exception on /predict_ndarray [POST] (trace=156950642083749234515564829508453262689,span=16045597061798152836,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/bentoml/_internal/server/service_app.py\", line 318, in api_func\n",
      "    output = await api.func(input_data)\n",
      "  File \"/Users/jpark/WorkDevEdgeAI/cloud-edge-aicontainers/v2/approaches/bentoML/01_torch_save/service.py\", line 34, in predict_ndarray\n",
      "    assert inp.shape == (28, 28)\n",
      "AssertionError\n",
      "2022-08-29T23:20:09+0900 [INFO] [dev_api_server] 127.0.0.1:55312 (scheme=http,method=POST,path=/predict_ndarray,type=application/json,length=7) (status=500,type=application/json,length=110) 1.794ms (trace=156950642083749234515564829508453262689,span=16045597061798152836,sampled=0)\n",
      "2022-08-29T23:20:20+0900 [INFO] [dev_api_server] 127.0.0.1:55668 (scheme=http,method=GET,path=/healthz,type=,length=) (status=200,type=text/plain; charset=utf-8,length=1) 1.978ms (trace=21787817157680480215209217021260515030,span=4159182029091652083,sampled=0)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service.py:svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c1b36",
   "metadata": {},
   "source": [
    "Now you can use something like:\n",
    "\n",
    "`curl -H \"Content-Type: multipart/form-data\" -F'fileobj=@samples/1.png;type=image/png' http://127.0.0.1:3000/predict_image`\n",
    "    \n",
    "to send an image to the digit recognition service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f03564",
   "metadata": {},
   "source": [
    "## Build a Bento for distribution and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207561bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bentoml' has no attribute 'build'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbentoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice.py:svc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.py\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m     exclude\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtests/\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile:./README.md\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     python\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      7\u001b[0m         packages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m     ),\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'bentoml' has no attribute 'build'"
     ]
    }
   ],
   "source": [
    "bentoml.build(\n",
    "    \"service.py:svc\",\n",
    "    include=[\"*.py\"],\n",
    "    exclude=[\"tests/\"],\n",
    "    description=\"file:./README.md\",\n",
    "    python=dict(\n",
    "        packages=[\"scikit-learn\", \"torch\", \"Pillow\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36306933",
   "metadata": {},
   "source": [
    "Starting a dev server with the Bento build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec4b9dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \u001b[31m[bentoml-cli] `serve` failed: Failed to load bento or import service 'pytorch_mnist_demo:latest'. If you are attempting to import bento in local store: `Failed to import module \"pytorch_mnist_demo\": No module named 'pytorch_mnist_demo'`, or if you are importing by python module path: `no Bentos with name 'pytorch_mnist_demo' exist in BentoML store <osfs '/Users/jpark/bentoml/bentos'>`\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve pytorch_mnist_demo:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fae93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b20ce2-2dbe-4221-b08c-5551dddb4d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "name": "pytorch_mnist.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
