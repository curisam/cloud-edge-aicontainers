{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4757315b-a1e5-4df8-ba8f-1181237afe40",
   "metadata": {},
   "source": [
    "# Make NN model\n",
    "\n",
    "- gRPC로 신경망 모델을 전달하는 실험을 위해 기 학습된 모델을 저장합니다.\n",
    "- 서버와 클라이언트 상호간에 전달을 수행하며, \"Netron\" 유틸리티로 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d094c681-9889-4bc7-b845-2a60bd31b773",
   "metadata": {},
   "source": [
    "## torch.hub 모델 목록을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09719a5-fb07-4d87-9f3b-9ca64aba4ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpark/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'deeplabv3_mobilenet_v3_large',\n",
       " 'deeplabv3_resnet101',\n",
       " 'deeplabv3_resnet50',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'fcn_resnet101',\n",
       " 'fcn_resnet50',\n",
       " 'googlenet',\n",
       " 'inception_v3',\n",
       " 'lraspp_mobilenet_v3_large',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.hub.list('pytorch/vision:v0.10.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f8e8ee-bf52-4e00-a3f0-9dbe9b6067bf",
   "metadata": {},
   "source": [
    "## vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e49b61b3-17f3-417f-a451-9fef27340e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.onnx\n",
    "\n",
    "# 1. 실제 사용하는 custom model을 불러와서 저장 가능\n",
    "model = torchvision.models.vgg16(pretrained=False)\n",
    "\n",
    "# 2. model의 파라미터를 OrderedDict 형태로 저장\n",
    "params = model.state_dict()\n",
    "\n",
    "# 3. 동적 그래프 형태의 pytorch model을 위하여 data를 model로 흘려주기 위한 더미 데이터 주입\n",
    "dummy_data = torch.empty(1, 3, 224, 224, dtype = torch.float32)\n",
    "\n",
    "# 4. onnx 파일을 export 함. 함수에는 차례대로 model, data, 저장할 파일명 순서대로 입력\n",
    "torch.onnx.export(model, dummy_data, \"checkpoint/vgg16.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862cfb3-3724-48ce-a476-a604b98d8c52",
   "metadata": {},
   "source": [
    "## Resnet, pth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1877a93a-fc75-4d91-867e-36ac52b7ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  resnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Save pth file\n",
    "import torch\n",
    "\n",
    "\n",
    "# Resnet\n",
    "model_names = ['resnet18', \n",
    "               'resnet34', \n",
    "               'resnet50', \n",
    "               'resnet101', \n",
    "               'resnet152']\n",
    "for name in model_names:\n",
    "    print('name = ', name)\n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', name, pretrained=True)\n",
    "    PATH = \"checkpoint/\" + name + '.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862b040c-edf1-4673-a992-919a815821da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  efficientnet_b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  efficientnet_b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  efficientnet_b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  efficientnet_b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  efficientnet_b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  efficientnet_b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  efficientnet_b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  efficientnet_b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  mobilenet_v2\n",
      "name =  mobilenet_v3_large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  mobilenet_v3_small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Efficient Net\n",
    "model_names = ['efficientnet_b0',\n",
    "               'efficientnet_b1',\n",
    "               'efficientnet_b2',\n",
    "               'efficientnet_b3',\n",
    "               'efficientnet_b4',\n",
    "               'efficientnet_b5',\n",
    "               'efficientnet_b6',\n",
    "               'efficientnet_b7',\n",
    "               'mobilenet_v2',\n",
    "               'mobilenet_v3_large',\n",
    "               'mobilenet_v3_small',\n",
    "              ]\n",
    "for name in model_names:\n",
    "    print('name = ', name)\n",
    "    model = torch.hub.load('pytorch/vision', name, pretrained=True)\n",
    "    PATH = \"checkpoint/\" + name + '.pth'\n",
    "    torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1019ce-8c37-4aec-8fcd-a1a1748d92d2",
   "metadata": {},
   "source": [
    "## Resnet, onnx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39db42e-4132-40dc-bf46-268f4be488e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Save onnx file\n",
    "import torch\n",
    "import torch.onnx \n",
    "\n",
    "# Efficient Net\n",
    "model_names = ['efficientnet_b0',\n",
    "               'efficientnet_b1',\n",
    "               'efficientnet_b2',\n",
    "               'efficientnet_b3',\n",
    "               'efficientnet_b4',\n",
    "               'efficientnet_b5',\n",
    "               'efficientnet_b6',\n",
    "               'efficientnet_b7',\n",
    "               'mobilenet_v2',\n",
    "               'mobilenet_v3_large',\n",
    "               'mobilenet_v3_small',\n",
    "              ]\n",
    "for name in model_names:\n",
    "    PATH = \"checkpoint/\" + name + '.onnx'\n",
    "    \n",
    "    model = torch.hub.load('pytorch/vision', name, pretrained=True)\n",
    "    #model.eval()\n",
    "\n",
    "    # 동적 그래프 형태의 pytorch model을 위하여 data를 model로 흘려주기 위한 더미 데이터 주입\n",
    "    dummy_data = torch.empty(1, 3, 224, 224, dtype = torch.float32)\n",
    "\n",
    "    # onnx 파일을 export 함. 함수에는 차례대로 model, data, 저장할 파일명 순서대로 입력\n",
    "    torch.onnx.export(model, dummy_data, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485889d-95d1-4a51-9297-f78ffa83cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save onnx file\n",
    "import torch\n",
    "import torch.onnx \n",
    "\n",
    "# Resnet\n",
    "model_names = ['resnet18', \n",
    "               'resnet34', \n",
    "               'resnet50', \n",
    "               'resnet101', \n",
    "               'resnet152']\n",
    "for name in model_names:\n",
    "    PATH = \"checkpoint/\" + name + '.onnx'\n",
    "    \n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', name, pretrained=True)\n",
    "    #model.eval()\n",
    "\n",
    "    # 동적 그래프 형태의 pytorch model을 위하여 data를 model로 흘려주기 위한 더미 데이터 주입\n",
    "    dummy_data = torch.empty(1, 3, 224, 224, dtype = torch.float32)\n",
    "\n",
    "    # onnx 파일을 export 함. 함수에는 차례대로 model, data, 저장할 파일명 순서대로 입력\n",
    "    torch.onnx.export(model, dummy_data, PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
