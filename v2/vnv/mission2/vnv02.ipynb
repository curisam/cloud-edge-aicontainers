{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a09739",
   "metadata": {},
   "source": [
    "# VnV (ver. 2)\n",
    "\n",
    "- JPark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a78184-a00c-4261-aaf6-8e7efebfdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#------------------------------------------------------\n",
    "# Config\n",
    "#------------------------------------------------------\n",
    "\n",
    "# Test images\n",
    "\n",
    "zip_images_url = 'http://keticmr.iptime.org:22080/edgeai/images/imagenet-mini-val.zip'\n",
    "zip_images = 'imagenet-mini-val.zip'\n",
    "dataset_root = './dataset'\n",
    "fpath_zip_images = dataset_root + '/' + zip_images\n",
    "fpath_testimages = dataset_root + '/imagenet-mini-val/'\n",
    "\n",
    "# Models\n",
    "#names = ['res18_weights.pth', 'res34_weights.pth', 'res50_weights.pth', 'res101_weights.pth', 'res152_weights.pth']\n",
    "names = ['resnet18-dict.pth', 'resnet34-dict.pth', 'resnet50-dict.pth', 'resnet101-dict.pth', 'resnet152-dict.pth']\n",
    "urlroot = 'http://keticmr.iptime.org:22080/edgeai/models_jpark/'\n",
    "modeldir = './checkpoint/'\n",
    "\n",
    "urlmodels = []\n",
    "for name in names:\n",
    "    urlmodels.append( urlroot + name )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745976a9-34c7-443b-a284-afc572efbf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip ./dataset/imagenet-mini-val.zip -d ./dataset\n",
      "Archive:  ./dataset/imagenet-mini-val.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replace ./dataset/__MACOSX/._imagenet-mini-val? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jpark/www/WorkDevEdgeAI/cloud-edge-aicontainers/v2/vnv/mission2/checkpoint'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#------------------------------------------------------\n",
    "# Download data\n",
    "#------------------------------------------------------\n",
    "import os\n",
    "# make download directory\n",
    "def makedir(path): \n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError: \n",
    "        if not os.path.isdir(path): \n",
    "            raise\n",
    "    return os.path.abspath(path)\n",
    "\n",
    "# Download images\n",
    "import urllib, os\n",
    "\n",
    "d = makedir(dataset_root) # 저장 공간 생성\n",
    "url, fname = (zip_images_url, fpath_zip_images)\n",
    "try: \n",
    "    urllib.URLopener().retrieve(url, fname)\n",
    "except: \n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "    \n",
    "\n",
    "# Unzip\n",
    "cmd = 'unzip ' + fpath_zip_images + ' -d ' + dataset_root\n",
    "print(cmd)\n",
    "os.system(cmd)\n",
    "\n",
    "# download models\n",
    "makedir(modeldir)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea3c945-e646-4a11-8144-50a8ba2b6de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d691860a9e1745e5993ff0b8f1b2a37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46834317.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a3841dcb184297a8e99e69769bfc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87326861.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dd3d7ba6b140f6ba2ff11da21ce549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102540417.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29861c873c04f27a150041c4dc8394b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=178814045.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332c26ae14454075a949c14f492182cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241669177.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "for name in names:\n",
    "    torch.hub.download_url_to_file(urlroot+name, modeldir+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73d6b4-49f6-4879-8618-0e0e3ce8fee6",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e2e5985-bf26-42b2-b782-26a4b09adcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------\n",
    "# Import packages\n",
    "#------------------------------------------------------\n",
    "import torch\n",
    "\n",
    "\n",
    "model_fpaths = []\n",
    "for name in names:\n",
    "    model_fpaths.append(modeldir + name)\n",
    "\n",
    "model_fpaths\n",
    "#print(model_fpaths)\n",
    "#print(urlroot+name)\n",
    "#print(modeldir+name)\n",
    "\n",
    "\n",
    "#------------------------------------------------------\n",
    "# initial models\n",
    "#------------------------------------------------------\n",
    "\n",
    "model_names = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "models = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    m = torch.hub.load('pytorch/vision:v0.10.0', model_name, pretrained=False)\n",
    "    models.append(m)\n",
    "    m.eval()\n",
    "    \n",
    "# load saved weigts to the initial model\n",
    "for idx, model in enumerate(models):\n",
    "    checkpoint = urlmodels[idx]\n",
    "    model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, progress=False))\n",
    "    model.eval()\n",
    "    print(idx)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77f07d7-965a-4646-875a-95c22f62b671",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1703d30-b54d-4ba2-8f8c-c9471f0c8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import iglob\n",
    "\n",
    "'''\n",
    "# read test files\n",
    "testfiles = []\n",
    "for fname in sorted( iglob(fpath_testimages + '**/*.JPEG', recursive=True) ):\n",
    "    testfiles.append(fname)\n",
    "'''\n",
    "\n",
    "idx_gt = []\n",
    "idx = 0\n",
    "testfiles = []\n",
    "for d in sorted( iglob(fpath_testimages + 'n*', recursive=False) ):\n",
    "    for fname in sorted( iglob(d + '/*.JPEG', recursive=True) ):\n",
    "        testfiles.append(fname)\n",
    "        idx_gt.append( idx )\n",
    "    idx += 1\n",
    "\n",
    "\n",
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "\n",
    "preproc = ['method1', 'method2']\n",
    "preproc_method = 'method1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aa4232f-83a3-457f-a2cc-74ad31b06e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'method2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754a0e23-769e-4a44-94e1-e6dc28c60157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b3e54-8600-410e-b26e-0bd439eb8b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "device =  cuda\n",
      "--------------------------------------------------\n",
      "model = resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3923/3923 [00:46<00:00, 84.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3358\n",
      "top1_cnt/n =  0.8559775681876115\n",
      "time =  46.201945543289185\n",
      "\n",
      "model = resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3923/3923 [00:47<00:00, 82.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3476\n",
      "top1_cnt/n =  0.8860565893448891\n",
      "time =  47.3156373500824\n",
      "\n",
      "model = resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3923/3923 [01:03<00:00, 62.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3545\n",
      "top1_cnt/n =  0.9036451695131277\n",
      "time =  63.21814465522766\n",
      "\n",
      "model = resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3923/3923 [01:43<00:00, 37.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3572\n",
      "top1_cnt/n =  0.9105276574050472\n",
      "time =  103.45815634727478\n",
      "\n",
      "model = resnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3923/3923 [02:10<00:00, 30.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3584\n",
      "top1_cnt/n =  0.9135865409125669\n",
      "time =  130.51422548294067\n",
      "\n",
      "--------------------------------------------------\n",
      "device =  cpu\n",
      "--------------------------------------------------\n",
      "model = resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3923/3923 [03:37<00:00, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3358\n",
      "top1_cnt/n =  0.8559775681876115\n",
      "time =  217.84603190422058\n",
      "\n",
      "model = resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3923/3923 [06:30<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3476\n",
      "top1_cnt/n =  0.8860565893448891\n",
      "time =  390.48020339012146\n",
      "\n",
      "model = resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3923/3923 [03:24<00:00, 19.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3545\n",
      "top1_cnt/n =  0.9036451695131277\n",
      "time =  204.8060154914856\n",
      "\n",
      "model = resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3923/3923 [05:14<00:00, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3572\n",
      "top1_cnt/n =  0.9105276574050472\n",
      "time =  314.93512892723083\n",
      "\n",
      "model = resnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 2205/3923 [04:03<02:52,  9.99it/s]"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "devices = ['cuda', 'cpu']\n",
    "for device in devices: \n",
    "    print('-'*50)\n",
    "    print('device = ', device, flush=True)\n",
    "    print('-'*50)\n",
    "\n",
    "    for model_idx, model in enumerate(models):\n",
    "        start = time.time() # timer\n",
    "        \n",
    "        print(f'model = {model_names[model_idx]}', flush=True)\n",
    "        top1_cnt = 0\n",
    "        top5_cnt = 0\n",
    "\n",
    "        testset = testfiles[:]\n",
    "        n = len(testset)\n",
    "        img_idx = 0\n",
    "    \n",
    "        # Define transforms for the evaluation phase\n",
    "        if preproc_method == preproc[0]:\n",
    "            preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                                  transforms.CenterCrop(224),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                            ])\n",
    "        else:\n",
    "            preprocess = transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "        for fpath in tqdm( testset ):\n",
    "            #print( fpath )\n",
    "            input_image = Image.open(fpath)\n",
    "\n",
    "            try:\n",
    "                input_tensor = preprocess(input_image)\n",
    "            except:\n",
    "                #print(img_idx)\n",
    "                # gray scale to color\n",
    "                input_image = Image.open(fpath).convert(\"RGB\")\n",
    "                input_tensor = preprocess(input_image)\n",
    "\n",
    "            input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "            \n",
    "            # move the input and model to GPU for speed if available\n",
    "            if device == 'cuda':\n",
    "                # move the input and model to GPU for speed if available\n",
    "                if torch.cuda.is_available():\n",
    "                    input_batch = input_batch.to('cuda')\n",
    "                    model.to('cuda')\n",
    "                else:\n",
    "                    print('[-] cuda cannot available')\n",
    "                    break\n",
    "            else:\n",
    "                input_batch = input_batch.to('cpu')\n",
    "                model.to('cpu')\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(input_batch)\n",
    "\n",
    "            # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "            #print(output[0])\n",
    "\n",
    "            # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "            probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "            #print(probabilities)\n",
    "\n",
    "            # Show top categories per image\n",
    "            top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "            for i in range(top5_prob.size(0)):\n",
    "                #print(top5_catid[i])\n",
    "                #pass\n",
    "                #print(idx, ' ', categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "                if( top5_catid[i] == idx_gt[img_idx] ):\n",
    "                    top1_cnt += 1\n",
    "\n",
    "            #print('')\n",
    "            img_idx += 1\n",
    "\n",
    "        end = time.time()\n",
    "        print('n = ', n)\n",
    "        print('top1_cnt = ', top1_cnt)\n",
    "        print('top1_cnt/n = ', top1_cnt/n)\n",
    "        print('time = ', end - start)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974601d1-3d8f-46c1-aa7c-ce9b2985135f",
   "metadata": {},
   "source": [
    "  0%|          | 11/3923 [00:00<00:37, 104.65it/s]\n",
    "--------------------------------------------------\n",
    "device =  cuda\n",
    "--------------------------------------------------\n",
    "model = resnet18\n",
    "100%|██████████| 3923/3923 [00:37<00:00, 103.82it/s]\n",
    "  0%|          | 9/3923 [00:00<00:43, 89.72it/s]\n",
    "n =  3923\n",
    "top1_cnt =  3358\n",
    "top1_cnt/n =  0.8559775681876115\n",
    "time =  37.79109072685242\n",
    "model = resnet34\n",
    "100%|██████████| 3923/3923 [00:45<00:00, 85.61it/s]\n",
    "  0%|          | 8/3923 [00:00<00:53, 72.95it/s]\n",
    "n =  3923\n",
    "top1_cnt =  3476\n",
    "top1_cnt/n =  0.8860565893448891\n",
    "time =  45.83013606071472\n",
    "model = resnet50\n",
    "100%|██████████| 3923/3923 [00:53<00:00, 73.31it/s]\n",
    "  0%|          | 0/3923 [00:00<?, ?it/s]\n",
    "n =  3923\n",
    "top1_cnt =  3545\n",
    "top1_cnt/n =  0.9036451695131277\n",
    "time =  53.516403675079346\n",
    "model = resnet101\n",
    "100%|██████████| 3923/3923 [01:20<00:00, 48.47it/s]\n",
    "  0%|          | 0/3923 [00:00<?, ?it/s]\n",
    "n =  3923\n",
    "top1_cnt =  3572\n",
    "top1_cnt/n =  0.9105276574050472\n",
    "time =  81.0622169971466\n",
    "model = resnet152\n",
    "100%|██████████| 3923/3923 [01:51<00:00, 35.12it/s]\n",
    "  0%|          | 0/3923 [00:00<?, ?it/s]\n",
    "n =  3923\n",
    "top1_cnt =  3584\n",
    "top1_cnt/n =  0.9135865409125669\n",
    "time =  111.86518239974976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec895e-2df1-406e-8b1a-aa523bdf4b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
