{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a09739",
   "metadata": {},
   "source": [
    "# VnV \n",
    "\n",
    "- JPark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28fbc8b-e6d4-4593-8f3c-d3c717f69b74",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9e7931-5994-40ea-b06a-c4a16183f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "\n",
    "zip_images_url = 'http://keticmr.iptime.org:22080/edgeai/images/imagenet-mini-val.zip'\n",
    "zip_images = 'imagenet-mini-val.zip'\n",
    "dataset_root = './dataset'\n",
    "fpath_zip_images = dataset_root + '/' + zip_images\n",
    "fpath_testimages = dataset_root + '/imagenet-mini-val/'\n",
    "\n",
    "# Models\n",
    "#names = ['res18_weights.pth', 'res34_weights.pth', 'res50_weights.pth', 'res101_weights.pth', 'res152_weights.pth']\n",
    "names = ['resnet18-dict.pth', 'resnet34-dict.pth', 'resnet50-dict.pth', 'resnet101-dict.pth', 'resnet152-dict.pth']\n",
    "urlroot = 'http://keticmr.iptime.org:22080/edgeai/models_jpark/'\n",
    "modeldir = './checkpoint/'\n",
    "\n",
    "urlmodels = []\n",
    "for name in names:\n",
    "    urlmodels.append( urlroot + name )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddd6ecd-6152-41b3-ae6d-56fcc92a17ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset/imagenet-mini-val.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath_zip_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7797a7-f2f4-4a98-b685-6c95ad7fa50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset/imagenet-mini-val/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath_testimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54451c7-92f2-41f6-bd08-f98174837d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet18-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet34-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet50-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet101-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet152-dict.pth']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da7b4c7",
   "metadata": {},
   "source": [
    "## 2. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7132770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cea09-0f69-4d0b-8cd3-815f4d8c663d",
   "metadata": {},
   "source": [
    "## 3. download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64ffe56-e5be-492a-93b9-556c809f248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# make download directory\n",
    "def makedir(path): \n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError: \n",
    "        if not os.path.isdir(path): \n",
    "            raise\n",
    "    return os.path.abspath(path)\n",
    "\n",
    "# Download images\n",
    "import urllib, os\n",
    "\n",
    "d = makedir(dataset_root) # 저장 공간 생성\n",
    "url, fname = (zip_images_url, fpath_zip_images)\n",
    "try: \n",
    "    urllib.URLopener().retrieve(url, fname)\n",
    "except: \n",
    "    urllib.request.urlretrieve(url, fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3156edce-b0a6-4022-9e00-f6f4f582567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip ./dataset/imagenet-mini-val.zip -d ./dataset\n",
      "Archive:  ./dataset/imagenet-mini-val.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replace ./dataset/__MACOSX/._imagenet-mini-val? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Unzip\n",
    "cmd = 'unzip ' + fpath_zip_images + ' -d ' + dataset_root\n",
    "print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73d6b4-49f6-4879-8618-0e0e3ce8fee6",
   "metadata": {},
   "source": [
    "## 4. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "483298b2-f985-4fba-8686-c3756ef2a156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dataset/imagenet-mini-val/n01440764/ILSVRC2012_val_00009111.JPEG',\n",
       " './dataset/imagenet-mini-val/n01440764/ILSVRC2012_val_00030740.JPEG']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfiles[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25aacc45-d173-493d-9a2d-90f68160bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4646811a-2136-4a6a-b035-fc547e10e7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812f2e25-fd8f-4d96-a1d7-e1acbe9fe3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tench',\n",
       " 'goldfish',\n",
       " 'great white shark',\n",
       " 'tiger shark',\n",
       " 'hammerhead',\n",
       " 'electric ray',\n",
       " 'stingray',\n",
       " 'cock',\n",
       " 'hen',\n",
       " 'ostrich']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "796b3e54-8600-410e-b26e-0bd439eb8b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▏                                                                    | 19/100 [00:01<00:05, 14.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  100\n",
      "top1_cnt =  95\n",
      "top1_cnt/n =  0.95\n",
      "time =  6.568495988845825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "'''\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "'''\n",
    "\n",
    "# Define transforms for the evaluation phase\n",
    "preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "\n",
    "model = models[0]\n",
    "\n",
    "top1_cnt = 0\n",
    "top5_cnt = 0\n",
    "\n",
    "testset = testfiles[:100]\n",
    "n = len(testset)\n",
    "idx = 0\n",
    "for fpath in tqdm( testset ):\n",
    "    #print( fpath )\n",
    "    input_image = Image.open(fpath)\n",
    "\n",
    "    try:\n",
    "        input_tensor = preprocess(input_image)\n",
    "    except:\n",
    "        #print(idx)\n",
    "        # gray scale to color\n",
    "        input_image = Image.open(fpath).convert(\"RGB\")\n",
    "        input_tensor = preprocess(input_image)\n",
    "\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "        \n",
    "    # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "    #print(output[0])\n",
    "    \n",
    "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    #print(probabilities)\n",
    "\n",
    "    \n",
    "    # Show top categories per image\n",
    "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "    for i in range(top5_prob.size(0)):\n",
    "        #print(top5_catid[i])\n",
    "        #pass\n",
    "        #print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "        \n",
    "        if( top5_catid[i] == idx_gt[idx] ):\n",
    "            top1_cnt += 1\n",
    "        \n",
    "    #print('')\n",
    "    idx += 1\n",
    "\n",
    "end = time.time()\n",
    "print('n = ', n)\n",
    "print('top1_cnt = ', top1_cnt)\n",
    "print('top1_cnt/n = ', top1_cnt/n)\n",
    "print('time = ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d211f-ecec-4e87-b7ec-c510cc0e6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n =  3923\n",
    "top1_cnt =  3519\n",
    "top1_cnt/n =  0.8970175885801682\n",
    "time =  99.26183104515076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abef25-1608-4e42-884f-cd099daaa740",
   "metadata": {},
   "outputs": [],
   "source": [
    "n =  3923\n",
    "top1_cnt =  3299\n",
    "top1_cnt/n =  0.8409380576089728\n",
    "time =  37.87246131896973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265d22a-a55b-49e2-8fe2-c5c6a117e6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e599f-52f1-497e-b1d7-51b2206ca744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21433d7-28c4-456b-a63a-9ecb6bf4c7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23509e23-a47b-4d4f-8c13-a47bba898209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base(conda)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
