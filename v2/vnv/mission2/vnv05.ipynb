{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a09739",
   "metadata": {},
   "source": [
    "# VnV (ver. 3)\n",
    "\n",
    "- by JPark\n",
    "- 모델 추가\n",
    "- 지연 시간 측정을 위한 코드 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a78184-a00c-4261-aaf6-8e7efebfdae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpark/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#------------------------------------------------------\n",
    "# Config\n",
    "#------------------------------------------------------\n",
    "\n",
    "# Test images\n",
    "\n",
    "zip_images_url = 'http://keticmr.iptime.org:22080/edgeai/images/imagenet-mini-val.zip'\n",
    "zip_images = 'imagenet-mini-val.zip'\n",
    "dataset_root = './dataset'\n",
    "fpath_zip_images = dataset_root + '/' + zip_images\n",
    "fpath_testimages = dataset_root + '/imagenet-mini-val/'\n",
    "\n",
    "# Models\n",
    "urlroot = 'http://keticmr.iptime.org:22080/edgeai/models_jpark/'\n",
    "modeldir = './checkpoint/'\n",
    "    \n",
    "model_names_resnet = [ \n",
    "    'resnet18',\n",
    "    'resnet34',\n",
    "    'resnet50',\n",
    "    'resnet101',\n",
    "    'resnet152',\n",
    "]\n",
    "repo_resnet = 'pytorch/vision:v0.10.0'\n",
    "\n",
    "model_names_mobnet = [\n",
    "    'mobilenet_v3_small',\n",
    "    'mobilenet_v3_large',\n",
    "]\n",
    "repo_mobnet = 'pytorch/vision:v0.10.0'\n",
    "\n",
    "'''\n",
    "model_names_effnet = [ \n",
    "    'nvidia_efficientnet_b0',\n",
    "    'nvidia_efficientnet_b4',\n",
    "    'nvidia_efficientnet_widese_b0',\n",
    "    'nvidia_efficientnet_widese_b4',\n",
    "]\n",
    "repo_effnet = 'NVIDIA/DeepLearningExamples:torchhub'\n",
    "'''\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model_names_effnet = [ \n",
    "    'efficientnet-b0',\n",
    "    'efficientnet-b1',\n",
    "    'efficientnet-b2',\n",
    "    'efficientnet-b3',\n",
    "    'efficientnet-b4',\n",
    "    'efficientnet-b5',\n",
    "    'efficientnet-b6',\n",
    "    'efficientnet-b7',\n",
    "]\n",
    "repo_effnet = ''\n",
    "\n",
    "\n",
    "\n",
    "model_names = model_names_resnet + model_names_effnet + model_names_mobnet\n",
    "#model_names = model_names_effnet\n",
    "\n",
    "\n",
    "pth_names = [ model_name + '-dict.pth' for model_name in model_names ]\n",
    "\n",
    "urlmodels = []\n",
    "for pth_name in pth_names:\n",
    "    urlmodels.append(urlroot + pth_name)\n",
    "\n",
    "model_fpaths = []\n",
    "for pth_name in pth_names:\n",
    "    model_fpaths.append(modeldir + pth_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c318fe-450d-4040-b263-2de5925379f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet18-dict.pth',\n",
       " 'resnet34-dict.pth',\n",
       " 'resnet50-dict.pth',\n",
       " 'resnet101-dict.pth',\n",
       " 'resnet152-dict.pth',\n",
       " 'efficientnet-b0-dict.pth',\n",
       " 'efficientnet-b1-dict.pth',\n",
       " 'efficientnet-b2-dict.pth',\n",
       " 'efficientnet-b3-dict.pth',\n",
       " 'efficientnet-b4-dict.pth',\n",
       " 'efficientnet-b5-dict.pth',\n",
       " 'efficientnet-b6-dict.pth',\n",
       " 'efficientnet-b7-dict.pth',\n",
       " 'mobilenet_v3_small-dict.pth',\n",
       " 'mobilenet_v3_large-dict.pth']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baaa203c-01ec-49d8-ad82-fe90b6be9cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet18-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet34-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet50-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet101-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet152-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b0-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b1-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b2-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b3-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b4-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b5-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b6-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b7-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/mobilenet_v3_small-dict.pth',\n",
       " 'http://keticmr.iptime.org:22080/edgeai/models_jpark/mobilenet_v3_large-dict.pth']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3a1026-1408-4aab-9ae7-6c75647e1295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./checkpoint/resnet18-dict.pth',\n",
       " './checkpoint/resnet34-dict.pth',\n",
       " './checkpoint/resnet50-dict.pth',\n",
       " './checkpoint/resnet101-dict.pth',\n",
       " './checkpoint/resnet152-dict.pth',\n",
       " './checkpoint/efficientnet-b0-dict.pth',\n",
       " './checkpoint/efficientnet-b1-dict.pth',\n",
       " './checkpoint/efficientnet-b2-dict.pth',\n",
       " './checkpoint/efficientnet-b3-dict.pth',\n",
       " './checkpoint/efficientnet-b4-dict.pth',\n",
       " './checkpoint/efficientnet-b5-dict.pth',\n",
       " './checkpoint/efficientnet-b6-dict.pth',\n",
       " './checkpoint/efficientnet-b7-dict.pth',\n",
       " './checkpoint/mobilenet_v3_small-dict.pth',\n",
       " './checkpoint/mobilenet_v3_large-dict.pth']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75e3e43-34e4-4ee6-9ac0-321f6889f08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset/imagenet-mini-val.zip'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath_zip_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0e7faf-8908-4c89-adb2-acca19e3e727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'efficientnet-b0',\n",
       " 'efficientnet-b1',\n",
       " 'efficientnet-b2',\n",
       " 'efficientnet-b3',\n",
       " 'efficientnet-b4',\n",
       " 'efficientnet-b5',\n",
       " 'efficientnet-b6',\n",
       " 'efficientnet-b7',\n",
       " 'mobilenet_v3_small',\n",
       " 'mobilenet_v3_large']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404f9e9-af78-4415-b385-99c520407e30",
   "metadata": {},
   "source": [
    "## 00. 사전작업\n",
    "\n",
    "- 사전으로 실험을 위한 디렉토리를 생성하고, 추론 영상을 다운로드 받습니다. (변인통제 요소)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745976a9-34c7-443b-a284-afc572efbf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading...\n",
      "[+] download skipped \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#------------------------------------------------------\n",
    "# Download data\n",
    "#------------------------------------------------------\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "# make download directory\n",
    "def makedir(path): \n",
    "    isdir = os.path.isdir(path)\n",
    "    \n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError: \n",
    "        if not isdir: \n",
    "            raise\n",
    "    return os.path.abspath(path), isdir\n",
    "\n",
    "# Download images\n",
    "d, isdir = makedir(dataset_root) # 저장 공간 생성\n",
    "\n",
    "if isdir:\n",
    "    url, fname = (zip_images_url, fpath_zip_images)\n",
    "    isfile_exist = os.path.exists(os.path.join(os.getcwd(), fname))\n",
    "    \n",
    "    print('downloading...')\n",
    "    if not isfile_exist:\n",
    "        try: \n",
    "            urllib.URLopener().retrieve(url, fname)\n",
    "        except: \n",
    "            urllib.request.urlretrieve(url, fname)\n",
    "        print('[+] download completed.')\n",
    "        # Unzip\n",
    "        cmd = 'unzip ' + fpath_zip_images + ' -d ' + dataset_root\n",
    "        print(cmd)\n",
    "        os.system(cmd)\n",
    "    else:\n",
    "        print('[+] download skipped ')\n",
    "\n",
    "\n",
    "from glob import iglob\n",
    "\n",
    "'''\n",
    "# read test files\n",
    "testfiles = []\n",
    "for fname in sorted( iglob(fpath_testimages + '**/*.JPEG', recursive=True) ):\n",
    "    testfiles.append(fname)\n",
    "'''\n",
    "\n",
    "idx_gt = []\n",
    "idx = 0\n",
    "testfiles = []\n",
    "for d in sorted( iglob(fpath_testimages + 'n*', recursive=False) ):\n",
    "    for fname in sorted( iglob(d + '/*.JPEG', recursive=True) ):\n",
    "        testfiles.append(fname)\n",
    "        idx_gt.append( idx )\n",
    "    idx += 1\n",
    "\n",
    "\n",
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6c0de-5ddb-4ba3-87c3-f4e018048b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e73d6b4-49f6-4879-8618-0e0e3ce8fee6",
   "metadata": {},
   "source": [
    "## 01. 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51491624-9b98-44af-8d7f-2d02fd2e238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3923"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3870e27e-5639-4149-aa75-4e61e2b0d90f",
   "metadata": {},
   "source": [
    "## GPU 동작모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796b3e54-8600-410e-b26e-0bd439eb8b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "device =  cuda\n",
      "--------------------------------------------------\n",
      "model = resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jpark/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jpark/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 3923/3923 [00:44<00:00, 88.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2500\n",
      "top1_acc =  0.637267397399949\n",
      "top5_cnt =  3358\n",
      "top5_acc =  0.8559775681876115\n",
      "time =  46.982306718826294\n",
      "\n",
      "model = resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet34-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/resnet34-dict.pth\n",
      "100%|██████████| 3923/3923 [00:49<00:00, 79.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2690\n",
      "top1_acc =  0.6856997196023451\n",
      "top5_cnt =  3476\n",
      "top5_acc =  0.8860565893448891\n",
      "time =  57.01204562187195\n",
      "\n",
      "model = resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet50-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/resnet50-dict.pth\n",
      "100%|██████████| 3923/3923 [00:58<00:00, 67.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2763\n",
      "top1_acc =  0.7043079276064237\n",
      "top5_cnt =  3545\n",
      "top5_acc =  0.9036451695131277\n",
      "time =  67.59566640853882\n",
      "\n",
      "model = resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet101-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/resnet101-dict.pth\n",
      "100%|██████████| 3923/3923 [01:31<00:00, 42.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2780\n",
      "top1_acc =  0.7086413459087433\n",
      "top5_cnt =  3571\n",
      "top5_acc =  0.9102727504460871\n",
      "time =  107.9017083644867\n",
      "\n",
      "model = resnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/resnet152-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/resnet152-dict.pth\n",
      "100%|██████████| 3923/3923 [02:05<00:00, 31.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2873\n",
      "top1_acc =  0.7323476930920214\n",
      "top5_cnt =  3584\n",
      "top5_acc =  0.9135865409125669\n",
      "time =  147.0339629650116\n",
      "\n",
      "model = efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n",
      "100%|██████████| 20.4M/20.4M [00:02<00:00, 9.29MB/s]\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b0-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b0-dict.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3923/3923 [01:14<00:00, 52.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2832\n",
      "top1_acc =  0.7218965077746623\n",
      "top5_cnt =  3555\n",
      "top5_acc =  0.9061942391027275\n",
      "time =  79.90104460716248\n",
      "\n",
      "model = efficientnet-b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b1-f1951068.pth\n",
      "100%|██████████| 30.1M/30.1M [00:03<00:00, 10.5MB/s]\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b1-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b1-dict.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3923/3923 [01:36<00:00, 40.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2897\n",
      "top1_acc =  0.7384654601070609\n",
      "top5_cnt =  3606\n",
      "top5_acc =  0.9191944940096864\n",
      "time =  103.48478055000305\n",
      "\n",
      "model = efficientnet-b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b2-8bb594d6.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b2-8bb594d6.pth\n",
      "100%|██████████| 35.1M/35.1M [00:03<00:00, 11.5MB/s]\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b2-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b2-dict.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3923/3923 [01:36<00:00, 40.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2862\n",
      "top1_acc =  0.7295437165434616\n",
      "top5_cnt =  3588\n",
      "top5_acc =  0.9146061687484068\n",
      "time =  104.00113654136658\n",
      "\n",
      "model = efficientnet-b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b3-5fb5a3c3.pth\n",
      "100%|██████████| 47.1M/47.1M [00:07<00:00, 6.58MB/s]\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b3-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b3-dict.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3923/3923 [01:47<00:00, 36.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2933\n",
      "top1_acc =  0.7476421106296202\n",
      "top5_cnt =  3618\n",
      "top5_acc =  0.9222533775172063\n",
      "time =  120.8660478591919\n",
      "\n",
      "model = efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n",
      "100%|██████████| 74.4M/74.4M [00:06<00:00, 11.6MB/s]\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b4-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b4-dict.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3923/3923 [02:06<00:00, 31.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2918\n",
      "top1_acc =  0.7438185062452205\n",
      "top5_cnt =  3607\n",
      "top5_acc =  0.9194494009686465\n",
      "time =  141.43334674835205\n",
      "\n",
      "model = efficientnet-b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b5-b6417697.pth\n",
      "100%|██████████| 117M/117M [00:44<00:00, 2.74MB/s] \n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b5-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b5-dict.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3923/3923 [02:30<00:00, 26.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2813\n",
      "top1_acc =  0.7170532755544227\n",
      "top5_cnt =  3554\n",
      "top5_acc =  0.9059393321437675\n",
      "time =  207.38236618041992\n",
      "\n",
      "model = efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b6-c76e70fd.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b6-c76e70fd.pth\n",
      "100%|██████████| 165M/165M [00:39<00:00, 4.35MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b6-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b6-dict.pth\n",
      "100%|██████████| 3923/3923 [02:47<00:00, 23.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2846\n",
      "top1_acc =  0.7254652052001019\n",
      "top5_cnt =  3568\n",
      "top5_acc =  0.9095080295692073\n",
      "time =  223.97268295288086\n",
      "\n",
      "model = efficientnet-b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n",
      "100%|██████████| 254M/254M [01:08<00:00, 3.89MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/efficientnet-b7-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/efficientnet-b7-dict.pth\n",
      "100%|██████████| 3923/3923 [03:20<00:00, 19.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2880\n",
      "top1_acc =  0.7341320418047412\n",
      "top5_cnt =  3588\n",
      "top5_acc =  0.9146061687484068\n",
      "time =  294.8718819618225\n",
      "\n",
      "model = mobilenet_v3_small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/mobilenet_v3_small-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/mobilenet_v3_small-dict.pth\n",
      "100%|██████████| 3923/3923 [00:51<00:00, 76.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2527\n",
      "top1_acc =  0.6441498852918685\n",
      "top5_cnt =  3353\n",
      "top5_acc =  0.8547030333928116\n",
      "time =  52.53261661529541\n",
      "\n",
      "model = mobilenet_v3_large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"http://keticmr.iptime.org:22080/edgeai/models_jpark/mobilenet_v3_large-dict.pth\" to /home/jpark/.cache/torch/hub/checkpoints/mobilenet_v3_large-dict.pth\n",
      "100%|██████████| 3923/3923 [00:56<00:00, 68.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  2810\n",
      "top1_acc =  0.7162885546775427\n",
      "top5_cnt =  3556\n",
      "top5_acc =  0.9064491460616875\n",
      "time =  59.010059118270874\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "'''\n",
    "# Define transforms for the evaluation phase\n",
    "preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "'''\n",
    "\n",
    "preproc = ['method1', 'method2']\n",
    "preproc_method = 'method1'\n",
    "\n",
    "#devices = ['cuda', 'cpu']\n",
    "devices = ['cuda']\n",
    "\n",
    "models = []\n",
    "\n",
    "testset = testfiles[:]\n",
    "n = len(testset)\n",
    "\n",
    "# 디바이스별 반복\n",
    "for device in devices: \n",
    "    print('-'*50)\n",
    "    print('device = ', device, flush=True)\n",
    "    print('-'*50)\n",
    "        \n",
    "    # 모델별 반복\n",
    "    for model_idx, model_name in enumerate(model_names):\n",
    "        start = time.time() # strt timer        \n",
    "        print(f'model = {model_names[model_idx]}', flush=True)\n",
    "        \n",
    "        # 모델 템플릿 다운로드 (from torch.hub)\n",
    "        if model_name in model_names_resnet:\n",
    "            model = torch.hub.load(repo_resnet, model_name, pretrained=False)\n",
    "        elif model_name in model_names_mobnet:\n",
    "            model = torch.hub.load(repo_mobnet, model_name, pretrained=False)\n",
    "        elif model_name in model_names_effnet:\n",
    "            #model = torch.hub.load(repo_effnet, model_name, pretrained=False)\n",
    "            model = EfficientNet.from_pretrained(model_name)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "        # 모델 가중치 다운로드 (from AI 모델 리포지토리)\n",
    "        if False:    \n",
    "            # 방법 1\n",
    "            pass\n",
    "        \n",
    "            # torch.hub.download_url_to_file(urlroot+pthnames[model_idx], modeldir+pthnames[model_idx])\n",
    "            # model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, progress=False))\n",
    "            # model.eval()\n",
    "        else:\n",
    "            # 방법 2\n",
    "            checkpoint = urlmodels[model_idx]\n",
    "            model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, progress=False))\n",
    "            model.eval().to(device) # change model to evauation mode (e.g. disable Dropout, BatchNorm)\n",
    "            models.append(model)\n",
    " \n",
    "        # 시험용 입력 영상\n",
    "        top1_cnt = 0\n",
    "        top5_cnt = 0\n",
    "              \n",
    "        # 시험용 입력 영상 전처리 (크기 및 컬러채널)\n",
    "        if preproc_method == preproc[0]:\n",
    "            preprocess = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "        else:\n",
    "            preprocess = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "        # 시험영상별 반복\n",
    "        imgidx = 0\n",
    "        for fpath in tqdm( testset ):\n",
    "        #for fpath in testset:\n",
    "            #print( fpath )\n",
    "            input_image = Image.open(fpath)\n",
    "\n",
    "            try:\n",
    "                input_tensor = preprocess(input_image)\n",
    "            except:\n",
    "                # gray scale to color\n",
    "                input_image = Image.open(fpath).convert(\"RGB\")\n",
    "                input_tensor = preprocess(input_image)\n",
    "\n",
    "            input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "            # 디바이스 설정\n",
    "            if device == 'cuda':\n",
    "                if torch.cuda.is_available():\n",
    "                    input_batch = input_batch.to('cuda')\n",
    "                    model.to('cuda')\n",
    "            else:\n",
    "                input_batch = input_batch.to('cpu')\n",
    "                model.to('cpu')\n",
    "              \n",
    "            with torch.no_grad():\n",
    "                output = model(input_batch)\n",
    "\n",
    "            # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "            #print(output[0])\n",
    "\n",
    "            # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "            probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "            #print(probabilities)\n",
    "\n",
    "            # Show top categories per image\n",
    "            top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "            for i in range(top5_prob.size(0)):\n",
    "                #print(top5_catid[i])\n",
    "                #print(imgidx, ' ', categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "                if( top5_catid[i] == idx_gt[imgidx] ):\n",
    "                    top5_cnt += 1\n",
    "                    \n",
    "            # Show top categories per image\n",
    "            top1_prob, top1_catid = torch.topk(probabilities, 1)\n",
    "            if( top1_catid[0] == idx_gt[imgidx] ):\n",
    "                top1_cnt += 1\n",
    " \n",
    "            imgidx += 1\n",
    "\n",
    "        end = time.time() # end timer\n",
    "        print('n = ', n)\n",
    "        print('top1_cnt = ', top1_cnt)\n",
    "        print('top1_acc = ', top1_cnt/n)\n",
    "        print('top5_cnt = ', top5_cnt)\n",
    "        print('top5_acc = ', top5_cnt/n)\n",
    "        print('time = ', end - start)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbe875-c290-44bb-aaab-894026d71fec",
   "metadata": {},
   "source": [
    "## CPU 동작모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44089a94-ce28-490e-bcd3-f8ae00b89346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "device =  cpu\n",
      "--------------------------------------------------\n",
      "model = resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "100%|██████████| 3923/3923 [01:55<00:00, 33.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3358\n",
      "top1_cnt/n =  0.8559775681876115\n",
      "time =  116.17684650421143\n",
      "\n",
      "model = resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "100%|██████████| 3923/3923 [03:01<00:00, 21.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3476\n",
      "top1_cnt/n =  0.8860565893448891\n",
      "time =  182.05406522750854\n",
      "\n",
      "model = resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "100%|██████████| 3923/3923 [03:44<00:00, 17.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3545\n",
      "top1_cnt/n =  0.9036451695131277\n",
      "time =  224.42821073532104\n",
      "\n",
      "model = resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "100%|██████████| 3923/3923 [06:06<00:00, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3572\n",
      "top1_cnt/n =  0.9105276574050472\n",
      "time =  367.11171436309814\n",
      "\n",
      "model = resnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "100%|██████████| 3923/3923 [08:18<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3584\n",
      "top1_cnt/n =  0.9135865409125669\n",
      "time =  499.18171405792236\n",
      "\n",
      "model = nvidia_efficientnet_b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "100%|██████████| 3923/3923 [01:52<00:00, 34.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3619\n",
      "top1_cnt/n =  0.9225082844761662\n",
      "time =  112.36311888694763\n",
      "\n",
      "model = nvidia_efficientnet_b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "100%|██████████| 3923/3923 [03:55<00:00, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3550\n",
      "top1_cnt/n =  0.9049197043079276\n",
      "time =  236.33543014526367\n",
      "\n",
      "model = nvidia_efficientnet_widese_b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "100%|██████████| 3923/3923 [01:52<00:00, 34.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3633\n",
      "top1_cnt/n =  0.9260769819016059\n",
      "time =  113.0606951713562\n",
      "\n",
      "model = nvidia_efficientnet_widese_b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "100%|██████████| 3923/3923 [04:01<00:00, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3516\n",
      "top1_cnt/n =  0.8962528677032883\n",
      "time =  242.02179408073425\n",
      "\n",
      "model = mobilenet_v3_small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "100%|██████████| 3923/3923 [00:59<00:00, 66.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3353\n",
      "top1_cnt/n =  0.8547030333928116\n",
      "time =  59.20183300971985\n",
      "\n",
      "model = mobilenet_v3_large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "100%|██████████| 3923/3923 [01:24<00:00, 46.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  3923\n",
      "top1_cnt =  3556\n",
      "top1_cnt/n =  0.9064491460616875\n",
      "time =  84.20090246200562\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "'''\n",
    "# Define transforms for the evaluation phase\n",
    "preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "'''\n",
    "\n",
    "preproc = ['method1', 'method2']\n",
    "preproc_method = 'method1'\n",
    "\n",
    "devices = ['cuda', 'cpu']\n",
    "devices = ['cpu']\n",
    "\n",
    "models = []\n",
    "\n",
    "\n",
    "testset = testfiles[:]\n",
    "n = len(testset)\n",
    "\n",
    "# 디바이스별 반복\n",
    "for device in devices: \n",
    "    print('-'*50)\n",
    "    print('device = ', device, flush=True)\n",
    "    print('-'*50)\n",
    "        \n",
    "    # 모델별 반복\n",
    "    for model_idx, model_name in enumerate(model_names):\n",
    "        start = time.time() # strt timer        \n",
    "        print(f'model = {model_names[model_idx]}', flush=True)\n",
    "        \n",
    "        # 모델 템플릿 다운로드 (from torch.hub)\n",
    "        if model_name in model_names_resnet:\n",
    "            model = torch.hub.load(repo_resnet, model_name, pretrained=False)\n",
    "        elif model_name in model_names_mobnet:\n",
    "            model = torch.hub.load(repo_mobnet, model_name, pretrained=False)\n",
    "        elif model_name in model_names_effnet:\n",
    "            model = torch.hub.load(repo_effnet, model_name, pretrained=False)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "        # 모델 가중치 다운로드 (from AI 모델 리포지토리)\n",
    "        if False:    \n",
    "            # 방법 1\n",
    "            pass\n",
    "        \n",
    "            # torch.hub.download_url_to_file(urlroot+pthnames[model_idx], modeldir+pthnames[model_idx])\n",
    "            # model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, progress=False))\n",
    "            # model.eval()\n",
    "        else:\n",
    "            # 방법 2\n",
    "            checkpoint = urlmodels[model_idx]\n",
    "            model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, progress=False))\n",
    "            model.eval().to(device) # change model to evauation mode (e.g. disable Dropout, BatchNorm)\n",
    "            models.append(model)\n",
    " \n",
    "        # 시험용 입력 영상\n",
    "        top1_cnt = 0\n",
    "        top5_cnt = 0\n",
    "              \n",
    "        # 시험용 입력 영상 전처리 (크기 및 컬러채널)\n",
    "        if preproc_method == preproc[0]:\n",
    "            preprocess = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "        else:\n",
    "            preprocess = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "        # 시험영상별 반복\n",
    "        imgidx = 0\n",
    "        for fpath in tqdm( testset ):\n",
    "        #for fpath in testset:\n",
    "            #print( fpath )\n",
    "            input_image = Image.open(fpath)\n",
    "\n",
    "            try:\n",
    "                input_tensor = preprocess(input_image)\n",
    "            except:\n",
    "                # gray scale to color\n",
    "                input_image = Image.open(fpath).convert(\"RGB\")\n",
    "                input_tensor = preprocess(input_image)\n",
    "\n",
    "            input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "            # 디바이스 설정\n",
    "            if device == 'cuda':\n",
    "                if torch.cuda.is_available():\n",
    "                    input_batch = input_batch.to('cuda')\n",
    "                    model.to('cuda')\n",
    "            else:\n",
    "                input_batch = input_batch.to('cpu')\n",
    "                model.to('cpu')\n",
    "              \n",
    "            with torch.no_grad():\n",
    "                output = model(input_batch)\n",
    "\n",
    "            # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "            #print(output[0])\n",
    "\n",
    "            # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "            probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "            #print(probabilities)\n",
    "\n",
    "            # Show top categories per image\n",
    "            top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "            for i in range(top5_prob.size(0)):\n",
    "                #print(top5_catid[i])\n",
    "                #print(imgidx, ' ', categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "                if( top5_catid[i] == idx_gt[imgidx] ):\n",
    "                    top1_cnt += 1\n",
    "\n",
    "            imgidx += 1\n",
    "\n",
    "        end = time.time() # end timer\n",
    "        print('n = ', n)\n",
    "        print('top1_cnt = ', top1_cnt)\n",
    "        print('top1_cnt/n = ', top1_cnt/n)\n",
    "        print('time = ', end - start)\n",
    "        print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
