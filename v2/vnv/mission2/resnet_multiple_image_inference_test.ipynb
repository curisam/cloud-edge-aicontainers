{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5087e5-6d3b-4294-b51f-791df18992f1",
   "metadata": {},
   "source": [
    "# Resnet Multiple Image Inference Test\n",
    "\n",
    "- original code : # https://pytorch.org/hub/pytorch_vision_resnet/\n",
    "- modified by : JPark, Sep. 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f021f6-81d5-4189-a5a7-56fef0ae5a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/jpark/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Make ONNX model\n",
    "import torch\n",
    "import torch.onnx\n",
    "import os\n",
    "\n",
    "def make_onnx_models(model_names = ['resnet18', 'resnet34']):\n",
    "    for model_name in model_names:\n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', model_name, pretrained=True)\n",
    "        # model.eval()\n",
    "        batch_size = 256\n",
    "        x = torch.randn(batch_size, 3, 32, 32, requires_grad=True)\n",
    "        fpath_model = \"./checkpoint/\" + model_name + \".onnx\"\n",
    "\n",
    "        torch.onnx.export(model,               # 실행될 모델\n",
    "                          x,                         # 모델 입력값 (튜플 또는 여러 입력값들도 가능)\n",
    "                          fpath_model,   # 모델 저장 경로 (파일 또는 파일과 유사한 객체 모두 가능)\n",
    "                          export_params=True,        # 모델 파일 안에 학습된 모델 가중치를 저장할지의 여부\n",
    "                          opset_version=10,          # 모델을 변환할 때 사용할 ONNX 버전\n",
    "                          do_constant_folding=True,  # 최적하시 상수폴딩을 사용할지의 여부\n",
    "                          input_names = ['input'],   # 모델의 입력값을 가리키는 이름\n",
    "                          output_names = ['output'], # 모델의 출력값을 가리키는 이름\n",
    "                          dynamic_axes={'input' : {0 : 'batch_size'},    # 가변적인 길이를 가진 차원\n",
    "                                        'output' : {0 : 'batch_size'}})\n",
    "\n",
    "\n",
    "model_names = [ \n",
    "    'resnet18',\n",
    "    'resnet34',\n",
    "    'resnet50',\n",
    "    'resnet101',\n",
    "    'resnet152', ]\n",
    "\n",
    "make_onnx_models(model_names = model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac177ed-564c-4f2f-9111-3e46b6ccd2c9",
   "metadata": {},
   "source": [
    "### # Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# ImageNet labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0198f19-dd65-44b9-8db3-3c34a0193ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.063608169555664\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for icnt in range(100):\n",
    "    input_image = Image.open(filename)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "        \n",
    "    # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "    #print(output[0])\n",
    "    \n",
    "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    #print(probabilities)\n",
    "\n",
    "    # Read the categories\n",
    "    with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip() for s in f.readlines()]\n",
    "    # Show top categories per image\n",
    "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "    for i in range(top5_prob.size(0)):\n",
    "        pass\n",
    "        #print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "        \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92c8eb-f62c-4773-873c-8bb1ca06ef15",
   "metadata": {},
   "source": [
    "## Test 실험결과\n",
    "\n",
    "- 100회 반복, M1 MacbookPro14, CPU mode\n",
    "\n",
    "```csv\n",
    "model, time[sec]\n",
    "resnet18, 9.702051162719727 \n",
    "resnet34, 15.428618907928467\n",
    "resnet50, 16.397982120513916\n",
    "resnet101, 25.44774293899536\n",
    "resnet152, 35.063608169555664\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base(conda)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
